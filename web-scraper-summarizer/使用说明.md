ç½‘é¡µçˆ¬å–å’ŒAIæ€»ç»“å·¥å…· ä½¿ç”¨è¯´æ˜

è¿™æ˜¯ä¸€ä¸ªå¼ºå¤§çš„ç½‘é¡µå†…å®¹çˆ¬å–å’ŒAIæ™ºèƒ½æ€»ç»“å·¥å…·ï¼Œå¯ä»¥å¸®ä½ å¿«é€Ÿè·å–ç½‘é¡µå†…å®¹å¹¶ç”Ÿæˆé«˜è´¨é‡çš„æ€»ç»“ã€‚

## ğŸš€ å¿«é€Ÿå¼€å§‹

### 1. å®‰è£…ä¾èµ–
```bash
# è¿›å…¥é¡¹ç›®ç›®å½•
cd web-scraper-summarizer

# å®‰è£…Pythonä¾èµ–
pip install -r requirements.txt
```

### 2. é…ç½®APIï¼ˆå·²é¢„é…ç½®ç¾å›¢Fridayï¼‰
æœ¬å·¥å…·å·²é¢„é…ç½®ç¾å›¢Fridayå¤§æ¨¡å‹ï¼Œå¯ç›´æ¥ä½¿ç”¨ï¼š
```bash
# ç›´æ¥ä½¿ç”¨ï¼ˆä½¿ç”¨é¢„é…ç½®çš„Friday APIï¼‰
python scrape_and_summarize.py "https://example.com"
```

å¦‚æœè¦ä½¿ç”¨å…¶ä»–APIï¼Œå¯ä»¥è®¾ç½®ç¯å¢ƒå˜é‡ï¼š
```bash
# ä½¿ç”¨OpenAI API
export OPENAI_API_KEY="your-api-key-here"
python scrape_and_summarize.py "https://example.com" --api-type openai

# ä½¿ç”¨è‡ªå®šä¹‰Fridayé…ç½®
export FRIDAY_APP_ID="your-app-id"
python scrape_and_summarize.py "https://example.com" --api-key "your-app-id"
```

### 3. ä¸€é”®è¿è¡Œ
```bash
# æœ€ç®€å•çš„ç”¨æ³•ï¼ˆä½¿ç”¨é¢„é…ç½®çš„Fridayï¼‰
python scrape_and_summarize.py "https://example.com"

# ä½¿ç”¨ä¸åŒçš„æ¨¡å‹
python scrape_and_summarize.py "https://example.com" --model "LongCat-13B-128K-Chat"

# ä½¿ç”¨OpenAI
python scrape_and_summarize.py "https://example.com" --api-type openai --api-key "your-openai-key"
```

## ğŸ“š è¯¦ç»†ä½¿ç”¨æ–¹æ³•

### ä¸»è¦å·¥å…·

#### 1. ä¸€ä½“åŒ–å·¥å…·ï¼ˆæ¨èï¼‰
`scrape_and_summarize.py` - ä¸€é”®å®Œæˆçˆ¬å–å’Œæ€»ç»“

```bash
# åŸºç¡€ç”¨æ³•
python scrape_and_summarize.py "ç½‘é¡µURL"

# å®Œæ•´å‚æ•°ç¤ºä¾‹
python scrape_and_summarize.py "https://example.com" \
    --summary-type comprehensive \
    --model gpt-3.5-turbo \
    --api-type openai \
    --api-key "your-key" \
    --output "my_summary" \
    --keep-scraped \
    --timeout 15
```

#### 2. å•ç‹¬çš„çˆ¬è™«å·¥å…·
`web_scraper.py` - åªè¿›è¡Œç½‘é¡µçˆ¬å–

```bash
# åŸºç¡€çˆ¬å–
python web_scraper.py "https://example.com"

# æŒ‡å®šè¾“å‡ºæ–‡ä»¶
python web_scraper.py "https://example.com" -o "scraped_content.json"
```

#### 3. å•ç‹¬çš„æ€»ç»“å·¥å…·
`ai_summarizer.py` - å¯¹å·²çˆ¬å–çš„å†…å®¹è¿›è¡Œæ€»ç»“

```bash
# æ€»ç»“å·²ä¿å­˜çš„å†…å®¹
python ai_summarizer.py "scraped_content.json"

# æŒ‡å®šæ€»ç»“ç±»å‹
python ai_summarizer.py "scraped_content.json" --type technical
```

## ğŸ¯ æ€»ç»“ç±»å‹è¯´æ˜

- **comprehensive** (é»˜è®¤): å…¨é¢æ€»ç»“ï¼ŒåŒ…å«æ¦‚è¿°ã€è¦ç‚¹ã€é‡è¦ä¿¡æ¯ç­‰
- **brief**: ç®€è¦æ€»ç»“ï¼Œ2-3å¥è¯æ¦‚æ‹¬ä¸»è¦å†…å®¹
- **technical**: æŠ€æœ¯è§’åº¦åˆ†æï¼Œæå–æŠ€æœ¯è¦ç‚¹å’Œæ¦‚å¿µ
- **academic**: å­¦æœ¯è§’åº¦åˆ†æï¼Œå…³æ³¨æ ¸å¿ƒè§‚ç‚¹å’Œè®ºè¯é€»è¾‘

## ğŸ¤– æ”¯æŒçš„AIæ¨¡å‹

### ç¾å›¢Fridayæ¨¡å‹ï¼ˆé»˜è®¤ï¼‰
- `LongCat-8B-128K-Chat` (é»˜è®¤ï¼Œæ”¯æŒé•¿æ–‡æœ¬)
- `LongCat-13B-128K-Chat` (æ›´å¼ºæ€§èƒ½)

### OpenAIæ¨¡å‹
- `gpt-3.5-turbo` (æ€§ä»·æ¯”é«˜)
- `gpt-4` (è´¨é‡æ›´é«˜ï¼Œæˆæœ¬æ›´é«˜)
- `gpt-4-turbo`

### æœ¬åœ°éƒ¨ç½²æ¨¡å‹
æ”¯æŒå…¼å®¹OpenAI APIæ ¼å¼çš„æœ¬åœ°æ¨¡å‹ï¼š
```bash
python scrape_and_summarize.py "https://example.com" \
    --api-type local \
    --base-url "http://localhost:8000/v1" \
    --model "chatglm"
```

## ğŸ“ ä½¿ç”¨ç¤ºä¾‹

### ç¤ºä¾‹1ï¼šæŠ€æœ¯æ–‡ç« æ€»ç»“
```bash
python scrape_and_summarize.py "https://tech-blog.com/article" \
    --summary-type technical \
    --output "tech_summary"
```

### ç¤ºä¾‹2ï¼šæ–°é—»å¿«é€Ÿæ€»ç»“
```bash
python scrape_and_summarize.py "https://news.com/article" \
    --summary-type brief
```

### ç¤ºä¾‹3ï¼šå­¦æœ¯è®ºæ–‡åˆ†æ
```bash
python scrape_and_summarize.py "https://arxiv.org/abs/xxxx" \
    --summary-type academic \
    --model gpt-4
```

### ç¤ºä¾‹4ï¼šä¿ç•™åŸå§‹å†…å®¹
```bash
python scrape_and_summarize.py "https://example.com" \
    --keep-scraped \
    --output "complete_analysis"
```

## ğŸ”§ é«˜çº§é…ç½®

### ç¯å¢ƒå˜é‡é…ç½®
```bash
# OpenAIé…ç½®
export OPENAI_API_KEY="your-key"
export OPENAI_BASE_URL="https://api.openai.com/v1"

# æœ¬åœ°æ¨¡å‹é…ç½®
export LOCAL_MODEL_URL="http://localhost:8000/v1"
export DEFAULT_MODEL="chatglm"
```

### æ‰¹é‡å¤„ç†è„šæœ¬
åˆ›å»ºä¸€ä¸ªæ‰¹é‡å¤„ç†å¤šä¸ªURLçš„è„šæœ¬ï¼š
```bash
#!/bin/bash
urls=(
    "https://example1.com"
    "https://example2.com"
    "https://example3.com"
)

for url in "${urls[@]}"; do
    echo "å¤„ç†: $url"
    python scrape_and_summarize.py "$url" --output "batch_$(date +%s)"
done
```

## ğŸ“ è¾“å‡ºæ–‡ä»¶è¯´æ˜

### çˆ¬å–å†…å®¹æ–‡ä»¶ (JSONæ ¼å¼)
```json
{
  "title": "ç½‘é¡µæ ‡é¢˜",
  "content": "æå–çš„æ–‡æœ¬å†…å®¹",
  "url": "åŸå§‹URL",
  "length": 12345,
  "timestamp": "2024-01-01T12:00:00"
}
```

### æ€»ç»“ç»“æœæ–‡ä»¶ (JSONæ ¼å¼)
```json
{
  "original_title": "åŸæ–‡æ ‡é¢˜",
  "original_url": "åŸå§‹URL",
  "summary_type": "comprehensive",
  "model_used": "gpt-3.5-turbo",
  "summary": "AIç”Ÿæˆçš„æ€»ç»“å†…å®¹",
  "original_length": 12345,
  "summary_length": 500,
  "timestamp": "2024-01-01T12:00:00"
}
```

## âš ï¸ æ³¨æ„äº‹é¡¹

1. **APIè´¹ç”¨**: ä½¿ç”¨OpenAI APIä¼šäº§ç”Ÿè´¹ç”¨ï¼Œå»ºè®®å…ˆç”¨gpt-3.5-turboæµ‹è¯•
2. **ç½‘ç«™é™åˆ¶**: æŸäº›ç½‘ç«™å¯èƒ½æœ‰åçˆ¬è™«æœºåˆ¶ï¼Œå¦‚é‡åˆ°é—®é¢˜å¯è°ƒæ•´è¯·æ±‚å¤´
3. **å†…å®¹é•¿åº¦**: è¶…é•¿å†…å®¹å¯èƒ½ä¼šè¢«æˆªæ–­ï¼Œæ³¨æ„æ¨¡å‹çš„tokené™åˆ¶
4. **ç½‘ç»œç¯å¢ƒ**: ç¡®ä¿ç½‘ç»œè¿æ¥ç¨³å®šï¼Œå¯è°ƒæ•´timeoutå‚æ•°

## ğŸ†˜ å¸¸è§é—®é¢˜

### Q: æç¤º"æ¨¡å—æœªæ‰¾åˆ°"é”™è¯¯
A: è¯·ç¡®ä¿å·²å®‰è£…æ‰€æœ‰ä¾èµ–ï¼š`pip install -r requirements.txt`

### Q: APIè°ƒç”¨å¤±è´¥
A: æ£€æŸ¥APIå¯†é’¥æ˜¯å¦æ­£ç¡®ï¼Œç½‘ç»œæ˜¯å¦æ­£å¸¸ï¼Œä½™é¢æ˜¯å¦å……è¶³

### Q: çˆ¬å–å¤±è´¥
A: å¯èƒ½æ˜¯ç½‘ç«™é™åˆ¶ï¼Œå°è¯•å¢åŠ timeoutæˆ–æ›´æ¢User-Agent

### Q: æ€»ç»“è´¨é‡ä¸æ»¡æ„
A: å°è¯•ä¸åŒçš„æ€»ç»“ç±»å‹æˆ–æ›´é«˜çº§çš„æ¨¡å‹ï¼ˆå¦‚gpt-4ï¼‰

## ğŸ‰ å¼€å§‹ä½¿ç”¨å§ï¼

ç°åœ¨ä½ å¯ä»¥å¼€å§‹ä½¿ç”¨è¿™ä¸ªå¼ºå¤§çš„å·¥å…·äº†ã€‚ç»™æˆ‘ä¸€ä¸ªç½‘é¡µé“¾æ¥ï¼Œæˆ‘å°±èƒ½å¸®ä½ å¿«é€Ÿè·å–å†…å®¹å¹¶ç”Ÿæˆæ™ºèƒ½æ€»ç»“ï¼

```bash
# ç«‹å³è¯•è¯•è¿™ä¸ªå‘½ä»¤
python scrape_and_summarize.py "ä½ çš„ç½‘é¡µé“¾æ¥"
id